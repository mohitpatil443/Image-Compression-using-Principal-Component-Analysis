# Image-Compression-using-Principal-Component-Analysis

## Why did I choose this project ?
While glancing through the algorithms in CLRS, I came across Huffman encoding algorithm and found it to be quite intriguing. Exploring it's wide range of applications, I was led to an image compression aspect of it white seemed quite interesting. However, Further research and a conversation with the professor revealed that PCA works for relatively a wide range of datasets as compared to Huffman encoding algorithm and PCA. This is how I came up with this project idea.

## What is the problem ? 
When it comes to humongous amount of data storage especially in the form of images, compression of these images becomes almost inevitable in order to optimize the tradeoff between storage and image quality. Also, For machine learning algorithms that need images of decent quality as an input, image compresssion can improve the running time of the algorithm drastically. There are many algorithms that can be used for image compression namely, Huffman Encoding, Run Length Encoding(RLE) etc. However, These algorithms are applicable to only specific types of datasets. On the other hand, Principal Component Analysis (PCA) can be used on a wide range of datasets. Thus, PCA seems to be a reasonable choice fro image compression.

